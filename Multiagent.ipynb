{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f54978-5832-40c6-a5be-764b4b4197ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/work/env/dev/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cac08eb-b4b4-4570-91bf-1af7ee6f74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "import math\n",
    "import faiss\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "#from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79016fb-3b7c-4824-98b5-072a22f7cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain_experimental.generative_agents import GenerativeAgent, GenerativeAgentMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff7c3db-91d3-4afe-9ec2-b374ec4806f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = \"Deepak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc1f67b5-184d-4979-b3e3-7632eb132a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = AzureChatOpenAI(deployment_name=os.getenv(\"AZURE_DEP_NAME\"),\n",
    "#                          openai_api_version=os.getenv(\"AZURE_VERSION\"),\n",
    "#                           openai_api_key=os.getenv(\"AZURE_KEY\"),\n",
    "#                            azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "#                      max_tokens=1500)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "llm = ChatOpenAI(temperature=.7, model_name=\"gpt-3.5-turbo\", max_tokens=1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87555a6e-2125-45c4-b087-2052dd61d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_score_fn(score:float) -> float:\n",
    "    \"\"\"Returns similarity score on scale [0,1]\"\"\"\n",
    "    return 1.0 - score/ math.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce815bf7-6355-437b-a376-0dfae8129ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_ENDPOINT\")\n",
    "# os.environ[\"api_key\"] = os.getenv(\"AZURE_KEY\")\n",
    "\n",
    "#from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\" Create new vector store retriever unique to the agent \"\"\"\n",
    "    # embeddings_model = AzureOpenAIEmbeddings(\n",
    "    #                 azure_deployment=os.getenv(\"AZURE_DEP_NAME\"),\n",
    "    #                 openai_api_version=os.getenv(\"AZURE_VERSION\"),\n",
    "    #                 openai_api_key = os.getenv(\"AZURE_KEY\"),\n",
    "    #                 azure_endpoint = os.getenv(\"AZURE_ENDPOINT\")\n",
    "    # )\n",
    "    embeddings_model = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {}, relevance_score_fn=relevance_score_fn)\n",
    "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15)\n",
    "\n",
    "\n",
    "#create_new_memory_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f563c22d-434a-4de2-a657-422b7f9d2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_ENDPOINT\")\n",
    "\n",
    "os.environ[\"api_key\"] = os.getenv(\"AZURE_KEY\")\n",
    "\n",
    "#print(os.getenv(\"AZURE_KEY\"))\n",
    "\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "# embeddings_model = AzureOpenAIEmbeddings(\n",
    "#                     azure_deployment=os.getenv(\"AZURE_DEP_NAME\"),\n",
    "#                     openai_api_version=os.getenv(\"AZURE_VERSION\"),\n",
    "#                     openai_api_key = os.getenv(\"AZURE_KEY\"),\n",
    "#                     azure_endpoint = os.getenv(\"AZURE_ENDPOINT\"),\n",
    "#                     model = \"gpt-35-turbo-16k\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af2030b7-f2cb-4ad6-8303-8b84726ce409",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexis_memory = GenerativeAgentMemory(llm=llm,\n",
    "                                      memory_retriever=create_new_memory_retriever(),\n",
    "                                      verbose=False,\n",
    "                                      reflection_threshold=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfe3565-c018-41ba-bc4a-9fffa58e8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexis = GenerativeAgent(\n",
    "    name=\"Alexis\",\n",
    "    age=30,\n",
    "    traits = \"curious, creative writer, world traveller\",\n",
    "    status= \"exploring the intersection of technology and storytelling\",\n",
    "    memory_retriever = create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory = alexis_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d009c3a-ec0c-4f25-82c6-8ce8192aac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alexis (age: 30)\n",
      "Innate traits: curious, creative writer, world traveller\n",
      "Alexis is a hardworking, organized, and detail-oriented individual with strong communication and problem-solving skills. She is dedicated to her work and always strives for excellence.\n"
     ]
    }
   ],
   "source": [
    "print(alexis.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3372f93-53af-45d1-ac5d-0dd2d2a6acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alexis (age: 30)\n",
      "Innate traits: curious, creative writer, world traveller\n",
      "Alexis is reflective, goal-oriented, enjoys nature and art, looks forward to new experiences and learning opportunities.\n"
     ]
    }
   ],
   "source": [
    "alexis_observations = [\n",
    "    \"Alexis recalls her morning walk in the park\",\n",
    "    \"Alexis feels excited about the new book she started reading\",\n",
    "    \"Alexis remembers her conversation with a close friend\",\n",
    "    \"Alexis thinks about the painting she saw at the art gallery\",\n",
    "    \"Alexis is planning to learn a new recipe for dinner\",\n",
    "    \"Alexis is lookin forward to her weekend trip\",\n",
    "    \"Alexis contemplates her goals for the month.\"\n",
    "]\n",
    "\n",
    "for observation in alexis_observations:\n",
    "    alexis.memory.add_memory(observation)\n",
    "\n",
    "print(alexis.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14555b28-baa9-423e-a929-47827481392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
    "    \"\"\" Help the notebook user interact with the agent \"\"\"\n",
    "    new_message = \"{0} says {1}\".format(USER_NAME, message)\n",
    "    return agent.generate_dialogue_response(new_message)[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e2055fc-2fc6-4f10-b212-b7b7d2e43451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexis said \"I enjoy writing, travelling, exploring nature, and experiencing new things. How about you, Deepak?\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(alexis, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57dfda50-0cc2-461d-a907-299db951f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexis_observations_day = [\n",
    "    \"Alexis starts her day with a refreshing yoga session.\",\n",
    "    \"Alexis spends her time writing in her journal.\",\n",
    "    \"Alexis experiments with a new recipe she found online.\"\n",
    "]\n",
    "\n",
    "for observation in alexis_observations_day:\n",
    "    alexis.memory.add_memory(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "405d8d9d-9d14-4780-bf33-113c71336bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAlexis starts her day with a refreshing yoga session.\u001b[0m Alexis feels energized and ready to tackle the day ahead.\n",
      "\u001b[32mAlexis spends her time writing in her journal.\u001b[0m Alexis finds solace and inspiration in her journal writing.\n",
      "\u001b[32mAlexis experiments with a new recipe she found online.\u001b[0m Alexis is excited to try out new flavors and expand her culinary skills.\n",
      "****************************************\n",
      "\u001b[34mAfter these observations, Alexis's Summary is :\n",
      " Name: Alexis (age: 30)\n",
      "Innate traits: curious, creative writer, world traveller\n",
      "Alexis is introspective, goal-oriented, enjoys journal writing, yoga, trying new recipes, and exploring different experiences such as traveling, nature, and reading. She is open-minded and curious about the world around her.\u001b[0m\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "for i, obeservation in enumerate(alexis_observations_day):\n",
    "    _, reaction = alexis.generate_reaction(obeservation)\n",
    "    print(colored(obeservation, \"green\"), reaction)\n",
    "    if ((i+1) % len(alexis_observations_day)) == 0:\n",
    "        print(\"*\" * 40)\n",
    "        print(colored(\"After these observations, Alexis's Summary is :\\n {0}\".format(alexis.get_summary(force_refresh=True)), \"blue\"))\n",
    "        print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e967cf2-6660-4f52-938c-123371cb8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan = GenerativeAgent(\n",
    "    name=\"Jordan\",\n",
    "    age=28,\n",
    "    traits = \"tech enthuist, avid gamer, foodie\",\n",
    "    status= \"navigating the world of tech startups\",\n",
    "    memory_retriever = create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory = alexis_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73870f69-7908-4f59-a8a8-74d7674a6921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Jordan (age: 28)\n",
      "Innate traits: tech enthuist, avid gamer, foodie\n",
      "Jordan is a multi-talented individual who excels in both gaming and coding. They are adventurous and open to trying new experiences, as seen by their love for trying new restaurants. Alexis, on the other hand, is creative and introspective, finding solace in journal writing, yoga, and exploring different forms of art and literature. They are also eager to learn, constantly seeking out new skills and knowledge through activities like cooking and reading.\n"
     ]
    }
   ],
   "source": [
    "jordan_observations = [\n",
    "    \"Jordan finished challenging coding project last night\",\n",
    "    \"Jordan won local gaming tournament over the weekend\",\n",
    "    \"Jordan tried new south indian restaurant and loved it\"\n",
    "    \n",
    "]\n",
    "\n",
    "for observation in jordan_observations:\n",
    "    jordan.memory.add_memory(observation)\n",
    "\n",
    "print(jordan.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bd4eebd-c113-47ba-8f32-1c0f8d70e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(agents: List[GenerativeAgent], initial_observation: str) -> None:\n",
    "    \"\"\" Runs conversation between agents \"\"\"\n",
    "    _, observation = agents[1].generate_reaction(initial_observation)\n",
    "    print(observation)\n",
    "    max_turns = 3\n",
    "    turn = 0\n",
    "    while turn<=max_turns:\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n",
    "            print(observation)\n",
    "            # observation = \"{0} said {1}\".format(agent.name, reaction)\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True\n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turn +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ec6b2e4-70a9-4aa9-8572-378f887fc94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan can respond with \"That's interesting, Alexis! Have you looked into VR art or AI-generated art?\"\n",
      "Alexis said \"That's a great suggestion, Jordan! I haven't looked into VR art or AI-generated art yet, but I'll definitely check them out. Thanks for the tip!\"\n",
      "Jordan said \"That's great to hear, Alexis! Let me know if you have any questions or need more recommendations. I'm always here to help with tech-related stuff. Enjoy exploring VR art and AI-generated art!\"\n",
      "Alexis said \"Thank you, Jordan! I'll definitely reach out if I have any questions. I appreciate your support and guidance in exploring these new technologies. Have a great day!\"\n",
      "Jordan said \"Thank you, Alexis! I'm glad I could help. Feel free to reach out anytime. Have a wonderful day!\"\n"
     ]
    }
   ],
   "source": [
    "agents = [alexis, jordan]\n",
    "ini_conversation = \"Alexis said: Hey Jordan, I have been exploring how technology influence creativity lately. Since you are into tech, I was wondering if you have seen something that can help me to undersatand.\"\n",
    "run_conversation(agents, ini_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3881b4e9-c2fa-415f-b61b-91f64c5c13a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexis said \"I was discussing my interest in exploring the intersection of technology and storytelling with Jordan. It\\'s such a fascinating topic to dive into! How about you, Deepak? Have you explored any interesting intersections lately?\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(alexis, \"What was your conversation with Jordan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c478b46-5b28-4521-8151-3a704004a035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jordan said \"I was discussing the intersection of technology and storytelling with Alexis. It\\'s such a fascinating topic to explore! How about you, Deepak? Have you been exploring any interesting intersections lately?\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(jordan, \"What was your conversation with Alexis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b93b7c5-8b29-4613-b32a-d63d2499be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trivia Question :: Who is father of AI?\n",
      "Alexis's Answer:: Alexis said \"I'm not sure, who is the Father of AI?\"\n",
      "Jordan's Answer:: Jordan said \"That's a great question! The Father of AI is often considered to be John McCarthy, who coined the term 'artificial intelligence' back in 1956. He was a pioneer in the field and made significant contributions to the development of AI. Have you heard of him before?\"\n",
      "Trivia Question :: What is the capital of India?\n",
      "Alexis's Answer:: Alexis said \"I believe the capital of India is New Delhi, known for its vibrant culture and historical landmarks.\"\n",
      "Jordan's Answer:: Jordan said \"That's correct, the capital of India is New Delhi! It's known for its rich culture and historical landmarks. Have you ever been there before?\"\n",
      "Trivia Question :: Where is Burj Khalifa?\n",
      "Alexis's Answer:: Alexis said \"It's located in Dubai, United Arab Emirates, and it's known for being the tallest building in the world. Have a great day!\"\n",
      "Jordan's Answer:: Jordan said \"It's located in Dubai, United Arab Emirates, and it's known for being the tallest building in the world. Have a great day!\"\n"
     ]
    }
   ],
   "source": [
    "def run_competitive_trivia(agents: List[GenerativeAgent], questions: list[str]) -> None:\n",
    "    for question in questions:\n",
    "        print(\"Trivia Question :: {0}\".format(question))\n",
    "        for agent in agents:\n",
    "            response = agent.generate_dialogue_response(question)[1]\n",
    "            print(\"{0}'s Answer:: {1}\".format(agent.name, response))\n",
    "\n",
    "\n",
    "agents = [alexis, jordan]\n",
    "questions = [\n",
    "    \"Who is father of AI?\",\n",
    "    \"What is the capital of India?\",\n",
    "    \"Where is Burj Khalifa?\"\n",
    "]\n",
    "run_competitive_trivia(agents, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03481fb1-c841-403c-8fe5-3be090afe9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    )-> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = \"{0}: \".format(self.name)\n",
    "        self.reset()\n",
    "    def reset(self) -> str:\n",
    "        self.message_history = [\"Here is the conversation so far\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applied the chatmodel to the message history\n",
    "        and return the message string\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenate {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(\"{0}: {1}\".format(name, message))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d718bee-ae2c-442a-9c2d-5df8748cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function = Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} for {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step +=1\n",
    "\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. Choose next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "        # 4. increment the time\n",
    "        self._step +=1\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a634d3e-3932-45b5-ba46-ba266538db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class BiddingDialogueAgent(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        system_message: SystemMessage,\n",
    "        bidding_template: PromptTemplate,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.bidding_template = bidding_template\n",
    "\n",
    "    def bid(self) -> str:\n",
    "        \"\"\"\n",
    "        Ask chat model to output a bid to speak\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables = [\"message_history\", \"recent_message\"],\n",
    "            template=self.bidding_template,\n",
    "        ).format(\n",
    "            message_history=\"\\n\".join(self.message_history),\n",
    "            recent_message = self.message_history[-1],\n",
    "        )\n",
    "        bid_string = self.model([SystemMessage(content=prompt)]).content\n",
    "        return bid_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb1e6d5d-8e0c-4af1-85ef-5286df3ff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CHALLENGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d51b026c-68df-429c-8f11-cc20ce4cced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [\"CTO\", \"CMO\", \"CEO\", \"Investor-Daniel\", \"Invester-Sandra\"]\n",
    "topic = \"Startup pitch on startup focussed on energy drinks with no caffeine\"\n",
    "word_limit = 15\n",
    "\n",
    "# define the simulation\n",
    "game_description = f\"\"\"Here is the topic for the startup pitch to investors Sandra and Daniel: {topic}.\n",
    "The participants are: {', '.join(character_names)}. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "509c4d10-c6d6-4214-820b-c98e20fd824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def select_next_speaker(step: int, agents=List[DialogueAgent]) -> int:\n",
    "    bids = []\n",
    "    for agent in agents:\n",
    "        bid = ask_for_bid(agent)\n",
    "        bids.append(bid)\n",
    "\n",
    "    # ramdomly select among multiple agents with the same bid\n",
    "    max_value = np.max(bids)\n",
    "    max_indices = np.where(bids == max_value)[0]\n",
    "    idx = np.random.choice(max_indices)\n",
    "    print(\"Bids::\")\n",
    "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
    "        print(\"\\t{0} bid: {1}\".format(agent.name, bid))\n",
    "        if i == idx:\n",
    "            selected_name = agent.name\n",
    "    print(\"Selected : {0}\".format(selected_name))\n",
    "    print(\"\\n\")\n",
    "    return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "280d5697-58e8-4a51-9e86-388a27ec6373",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'character_system_messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m characters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m character_name, character_system_message, bidding_template \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m----> 4\u001b[0m     character_names, \u001b[43mcharacter_system_messages\u001b[49m, character_bidding_templates\n\u001b[1;32m      5\u001b[0m ):\n\u001b[1;32m      6\u001b[0m     characters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m      7\u001b[0m         BiddingDialogAgent(\n\u001b[1;32m      8\u001b[0m             name\u001b[38;5;241m=\u001b[39mcharacter_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         )\n\u001b[1;32m     12\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'character_system_messages' is not defined"
     ]
    }
   ],
   "source": [
    "characters = []\n",
    "model = ChatOpenAI(temperature=0.4)\n",
    "for character_name, character_system_message, bidding_template in zip(\n",
    "    character_names, character_system_messages, character_bidding_templates\n",
    "):\n",
    "    characters.append(\n",
    "        BiddingDialogAgent(\n",
    "            name=character_name,\n",
    "            system_message=character_system_messages,\n",
    "            bidding_template=character_bidding_templates\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5153162b-066c-4244-bfc7-68aff0620490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderator: CEO, CMO, CTO You can start pitching your ideas to out investor Sandra and Deniel\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m<\u001b[39m max_iters:\n\u001b[0;32m---> 12\u001b[0m     name, message \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, message))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 29\u001b[0m, in \u001b[0;36mDialogueSimulator.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# 1. Choose next speaker\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     speaker_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_next_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[speaker_idx]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# 2. next speaker sends message\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 9\u001b[0m, in \u001b[0;36mselect_next_speaker\u001b[0;34m(step, agents)\u001b[0m\n\u001b[1;32m      6\u001b[0m     bids\u001b[38;5;241m.\u001b[39mappend(bid)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ramdomly select among multiple agents with the same bid\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m max_value \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m max_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(bids \u001b[38;5;241m==\u001b[39m max_value)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(max_indices)\n",
      "File \u001b[0;32m~/work/env/dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/env/dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "max_iters = 10\n",
    "n = 0\n",
    "simulator = DialogueSimulator(agents=characters, selection_function=select_next_speaker)\n",
    "simulator.reset()\n",
    "\n",
    "first_message = \"CEO, CMO, CTO You can start pitching your ideas to out investor Sandra and Deniel\"\n",
    "simulator.inject(\"moderator\", first_message)\n",
    "\n",
    "print(\"Moderator: {0}\".format(first_message))\n",
    "print(\"\\n\")\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(\"{0}: {1}\".format(name, message))\n",
    "    print(\"\\n\")\n",
    "    n +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "927265c5-70a4-4516-a712-c8a8e48e779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ad689-a3e7-4337-8639-5f36c3f08c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
