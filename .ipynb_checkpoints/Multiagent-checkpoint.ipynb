{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f54978-5832-40c6-a5be-764b4b4197ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cac08eb-b4b4-4570-91bf-1af7ee6f74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "import math\n",
    "import faiss\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "#from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79016fb-3b7c-4824-98b5-072a22f7cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain_experimental.generative_agents import GenerativeAgent, GenerativeAgentMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff7c3db-91d3-4afe-9ec2-b374ec4806f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = \"Deepak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1f67b5-184d-4979-b3e3-7632eb132a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# llm = AzureChatOpenAI(deployment_name=os.getenv(\"AZURE_DEP_NAME\"),\n",
    "#                          openai_api_version=os.getenv(\"AZURE_VERSION\"),\n",
    "#                           openai_api_key=os.getenv(\"AZURE_KEY\"),\n",
    "#                            azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "#                      max_tokens=1500)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "llm = ChatOpenAI(temperature=.7, model_name=\"gpt-3.5-turbo\", max_tokens=1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87555a6e-2125-45c4-b087-2052dd61d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_score_fn(score:float) -> float:\n",
    "    \"\"\"Returns similarity score on scale [0,1]\"\"\"\n",
    "    return 1.0 - score/ math.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce815bf7-6355-437b-a376-0dfae8129ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_ENDPOINT\")\n",
    "# os.environ[\"api_key\"] = os.getenv(\"AZURE_KEY\")\n",
    "\n",
    "#from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\" Create new vector store retriever unique to the agent \"\"\"\n",
    "    # embeddings_model = AzureOpenAIEmbeddings(\n",
    "    #                 azure_deployment=os.getenv(\"AZURE_DEP_NAME\"),\n",
    "    #                 openai_api_version=os.getenv(\"AZURE_VERSION\"),\n",
    "    #                 openai_api_key = os.getenv(\"AZURE_KEY\"),\n",
    "    #                 azure_endpoint = os.getenv(\"AZURE_ENDPOINT\")\n",
    "    # )\n",
    "    embeddings_model = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {}, relevance_score_fn=relevance_score_fn)\n",
    "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15)\n",
    "\n",
    "\n",
    "#create_new_memory_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f563c22d-434a-4de2-a657-422b7f9d2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_ENDPOINT\")\n",
    "\n",
    "os.environ[\"api_key\"] = os.getenv(\"AZURE_KEY\")\n",
    "\n",
    "#print(os.getenv(\"AZURE_KEY\"))\n",
    "\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "# embeddings_model = AzureOpenAIEmbeddings(\n",
    "#                     azure_deployment=os.getenv(\"AZURE_DEP_NAME\"),\n",
    "#                     openai_api_version=os.getenv(\"AZURE_VERSION\"),\n",
    "#                     openai_api_key = os.getenv(\"AZURE_KEY\"),\n",
    "#                     azure_endpoint = os.getenv(\"AZURE_ENDPOINT\"),\n",
    "#                     model = \"gpt-35-turbo-16k\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2030b7-f2cb-4ad6-8303-8b84726ce409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "alexis_memory = GenerativeAgentMemory(llm=llm,\n",
    "                                      memory_retriever=create_new_memory_retriever(),\n",
    "                                      verbose=False,\n",
    "                                      reflection_threshold=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abfe3565-c018-41ba-bc4a-9fffa58e8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexis = GenerativeAgent(\n",
    "    name=\"Alexis\",\n",
    "    age=30,\n",
    "    traits = \"curious, creative writer, world traveller\",\n",
    "    status= \"exploring the intersection of technology and storytelling\",\n",
    "    memory_retriever = create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory = alexis_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d009c3a-ec0c-4f25-82c6-8ce8192aac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alexis (age: 30)\n",
      "Innate traits: curious, creative writer, world traveller\n",
      "Alexis is a hardworking, organized, and detail-oriented individual with strong communication and problem-solving skills. She is dedicated to her work and always strives for excellence.\n"
     ]
    }
   ],
   "source": [
    "print(alexis.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3372f93-53af-45d1-ac5d-0dd2d2a6acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alexis (age: 30)\n",
      "Innate traits: curious, creative writer, world traveller\n",
      "Alexis is reflective, goal-oriented, enjoys nature and art, looks forward to new experiences and learning opportunities.\n"
     ]
    }
   ],
   "source": [
    "alexis_observations = [\n",
    "    \"Alexis recalls her morning walk in the park\",\n",
    "    \"Alexis feels excited about the new book she started reading\",\n",
    "    \"Alexis remembers her conversation with a close friend\",\n",
    "    \"Alexis thinks about the painting she saw at the art gallery\",\n",
    "    \"Alexis is planning to learn a new recipe for dinner\",\n",
    "    \"Alexis is lookin forward to her weekend trip\",\n",
    "    \"Alexis contemplates her goals for the month.\"\n",
    "]\n",
    "\n",
    "for observation in alexis_observations:\n",
    "    alexis.memory.add_memory(observation)\n",
    "\n",
    "print(alexis.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14555b28-baa9-423e-a929-47827481392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
    "    \"\"\" Help the notebook user interact with the agent \"\"\"\n",
    "    new_message = \"{0} says {1}\".format(USER_NAME, message)\n",
    "    return agent.generate_dialogue_response(new_message)[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e2055fc-2fc6-4f10-b212-b7b7d2e43451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexis said \"I enjoy writing, travelling, exploring nature, and experiencing new things. How about you, Deepak?\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(alexis, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57dfda50-0cc2-461d-a907-299db951f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexis_observations_day = [\n",
    "    \"Alexis starts her day with a refreshing yoga session.\",\n",
    "    \"Alexis spends her time writing in her journal.\",\n",
    "    \"Alexis experiments with a new recipe she found online.\"\n",
    "]\n",
    "\n",
    "for observation in alexis_observations_day:\n",
    "    alexis.memory.add_memory(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "405d8d9d-9d14-4780-bf33-113c71336bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAlexis starts her day with a refreshing yoga session.\u001b[0m Alexis feels energized and ready to tackle the day ahead.\n",
      "\u001b[32mAlexis spends her time writing in her journal.\u001b[0m Alexis finds solace and inspiration in her journal writing.\n",
      "\u001b[32mAlexis experiments with a new recipe she found online.\u001b[0m Alexis is excited to try out new flavors and expand her culinary skills.\n",
      "****************************************\n",
      "\u001b[34mAfter these observations, Alexis's Summary is :\n",
      " Name: Alexis (age: 30)\n",
      "Innate traits: curious, creative writer, world traveller\n",
      "Alexis is introspective, goal-oriented, enjoys journal writing, yoga, trying new recipes, and exploring different experiences such as traveling, nature, and reading. She is open-minded and curious about the world around her.\u001b[0m\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "for i, obeservation in enumerate(alexis_observations_day):\n",
    "    _, reaction = alexis.generate_reaction(obeservation)\n",
    "    print(colored(obeservation, \"green\"), reaction)\n",
    "    if ((i+1) % len(alexis_observations_day)) == 0:\n",
    "        print(\"*\" * 40)\n",
    "        print(colored(\"After these observations, Alexis's Summary is :\\n {0}\".format(alexis.get_summary(force_refresh=True)), \"blue\"))\n",
    "        print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e967cf2-6660-4f52-938c-123371cb8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan = GenerativeAgent(\n",
    "    name=\"Jordan\",\n",
    "    age=28,\n",
    "    traits = \"tech enthuist, avid gamer, foodie\",\n",
    "    status= \"navigating the world of tech startups\",\n",
    "    memory_retriever = create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory = alexis_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73870f69-7908-4f59-a8a8-74d7674a6921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Jordan (age: 28)\n",
      "Innate traits: tech enthuist, avid gamer, foodie\n",
      "Jordan is a multi-talented individual who excels in both gaming and coding. They are adventurous and open to trying new experiences, as seen by their love for trying new restaurants. Alexis, on the other hand, is creative and introspective, finding solace in journal writing, yoga, and exploring different forms of art and literature. They are also eager to learn, constantly seeking out new skills and knowledge through activities like cooking and reading.\n"
     ]
    }
   ],
   "source": [
    "jordan_observations = [\n",
    "    \"Jordan finished challenging coding project last night\",\n",
    "    \"Jordan won local gaming tournament over the weekend\",\n",
    "    \"Jordan tried new south indian restaurant and loved it\"\n",
    "    \n",
    "]\n",
    "\n",
    "for observation in jordan_observations:\n",
    "    jordan.memory.add_memory(observation)\n",
    "\n",
    "print(jordan.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bd4eebd-c113-47ba-8f32-1c0f8d70e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(agents: List[GenerativeAgent], initial_observation: str) -> None:\n",
    "    \"\"\" Runs conversation between agents \"\"\"\n",
    "    _, observation = agents[1].generate_reaction(initial_observation)\n",
    "    print(observation)\n",
    "    max_turns = 3\n",
    "    turn = 0\n",
    "    while turn<=max_turns:\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n",
    "            print(observation)\n",
    "            # observation = \"{0} said {1}\".format(agent.name, reaction)\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True\n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turn +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ec6b2e4-70a9-4aa9-8572-378f887fc94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan can respond with \"That's interesting, Alexis! Have you looked into VR art or AI-generated art?\"\n",
      "Alexis said \"That's a great suggestion, Jordan! I haven't looked into VR art or AI-generated art yet, but I'll definitely check them out. Thanks for the tip!\"\n",
      "Jordan said \"That's great to hear, Alexis! Let me know if you have any questions or need more recommendations. I'm always here to help with tech-related stuff. Enjoy exploring VR art and AI-generated art!\"\n",
      "Alexis said \"Thank you, Jordan! I'll definitely reach out if I have any questions. I appreciate your support and guidance in exploring these new technologies. Have a great day!\"\n",
      "Jordan said \"Thank you, Alexis! I'm glad I could help. Feel free to reach out anytime. Have a wonderful day!\"\n"
     ]
    }
   ],
   "source": [
    "agents = [alexis, jordan]\n",
    "ini_conversation = \"Alexis said: Hey Jordan, I have been exploring how technology influence creativity lately. Since you are into tech, I was wondering if you have seen something that can help me to undersatand.\"\n",
    "run_conversation(agents, ini_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3881b4e9-c2fa-415f-b61b-91f64c5c13a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexis said \"I was discussing my interest in exploring the intersection of technology and storytelling with Jordan. It\\'s such a fascinating topic to dive into! How about you, Deepak? Have you explored any interesting intersections lately?\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(alexis, \"What was your conversation with Jordan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c478b46-5b28-4521-8151-3a704004a035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jordan said \"I was discussing the intersection of technology and storytelling with Alexis. It\\'s such a fascinating topic to explore! How about you, Deepak? Have you been exploring any interesting intersections lately?\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(jordan, \"What was your conversation with Alexis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b93b7c5-8b29-4613-b32a-d63d2499be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trivia Question :: Who is father of AI?\n",
      "Alexis's Answer:: Alexis said \"I'm not sure, who is the Father of AI?\"\n",
      "Jordan's Answer:: Jordan said \"That's a great question! The Father of AI is often considered to be John McCarthy, who coined the term 'artificial intelligence' back in 1956. He was a pioneer in the field and made significant contributions to the development of AI. Have you heard of him before?\"\n",
      "Trivia Question :: What is the capital of India?\n",
      "Alexis's Answer:: Alexis said \"I believe the capital of India is New Delhi, known for its vibrant culture and historical landmarks.\"\n",
      "Jordan's Answer:: Jordan said \"That's correct, the capital of India is New Delhi! It's known for its rich culture and historical landmarks. Have you ever been there before?\"\n",
      "Trivia Question :: Where is Burj Khalifa?\n",
      "Alexis's Answer:: Alexis said \"It's located in Dubai, United Arab Emirates, and it's known for being the tallest building in the world. Have a great day!\"\n",
      "Jordan's Answer:: Jordan said \"It's located in Dubai, United Arab Emirates, and it's known for being the tallest building in the world. Have a great day!\"\n"
     ]
    }
   ],
   "source": [
    "def run_competitive_trivia(agents: List[GenerativeAgent], questions: list[str]) -> None:\n",
    "    for question in questions:\n",
    "        print(\"Trivia Question :: {0}\".format(question))\n",
    "        for agent in agents:\n",
    "            response = agent.generate_dialogue_response(question)[1]\n",
    "            print(\"{0}'s Answer:: {1}\".format(agent.name, response))\n",
    "\n",
    "\n",
    "agents = [alexis, jordan]\n",
    "questions = [\n",
    "    \"Who is father of AI?\",\n",
    "    \"What is the capital of India?\",\n",
    "    \"Where is Burj Khalifa?\"\n",
    "]\n",
    "run_competitive_trivia(agents, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03481fb1-c841-403c-8fe5-3be090afe9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    )-> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = \"{0}: \".format(self.name)\n",
    "        self.reset()\n",
    "    def reset(self) -> str:\n",
    "        self.message_history = [\"Here is the conversation so far\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applied the chatmodel to the message history\n",
    "        and return the message string\n",
    "        \"\"\"\n",
    "        print(\"HHHHHHHHHHHHHH, \", self.message_history)\n",
    "        print(\"PPPPPPPPPPPPPP\", self.prefix)\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenate {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(\"{0}: {1}\".format(name, message))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d718bee-ae2c-442a-9c2d-5df8748cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function = Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} for {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step +=1\n",
    "\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. Choose next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "        # 4. increment the time\n",
    "        self._step +=1\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a634d3e-3932-45b5-ba46-ba266538db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class BiddingDialogueAgent(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        system_message: SystemMessage,\n",
    "        bidding_template: PromptTemplate,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.bidding_template = bidding_template\n",
    "\n",
    "    def bid(self) -> str:\n",
    "        \"\"\"\n",
    "        Ask chat model to output a bid to speak\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables = [\"message_history\", \"recent_message\"],\n",
    "            template=self.bidding_template,\n",
    "        ).format(\n",
    "            message_history=\"\\n\".join(self.message_history),\n",
    "            recent_message = self.message_history[-1],\n",
    "        )\n",
    "        bid_string = self.model([SystemMessage(content=prompt)]).content\n",
    "        return bid_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb1e6d5d-8e0c-4af1-85ef-5286df3ff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CHALLENGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d51b026c-68df-429c-8f11-cc20ce4cced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [\"CTO\", \"CMO\", \"CEO\", \"Investor-Daniel\", \"Invester-Sandra\"]\n",
    "topic = \"Startup pitch on startup focussed on energy drinks with no caffeine\"\n",
    "word_limit = 15\n",
    "\n",
    "# define the simulation\n",
    "game_description = f\"\"\"Here is the topic for the startup pitch to investors Sandra and Daniel: {topic}.\n",
    "The participants are: {', '.join(character_names)}. \"\"\"\n",
    "#character_system_messages =[f\"\"\"You are {name}. \"\"\"]\n",
    "\n",
    "# System Messages\n",
    "def generate_character_system_message(name, description):\n",
    "    return f\"\"\"Your name is {name}.\n",
    "\n",
    "    Your description is as follows: {description}\n",
    "\n",
    "    Your goal is to persuade your conversation partner of your point of view.\n",
    "\n",
    "    Stop speaking the moment you finish speaking of your perspective.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "character_system_messages = [generate_character_system_message(name, game_description) for name in character_names]\n",
    "bidding_template = f\"\"\"## Turn Bidding Template\n",
    "\n",
    "### Introduction\n",
    "- **Role:** <role>\n",
    "- **Context:** {game_description}\n",
    "\n",
    "### Bidding\n",
    "- **Bid Value:** [Specify the bid value, e.g., a numerical score or priority level]\n",
    "- **Reasoning:** [Explain why the agent believes it should have the turn to speak]\n",
    "\n",
    " \"\"\"\n",
    "#character_bidding_templates = [bidding_template.replace(\"<role>\", name) for name in character_names]\n",
    "character_bidding_templates = [game_description]*len(character_names)\n",
    "import numpy as np\n",
    "\n",
    "def ask_for_bid(agent):\n",
    "    return np.random.uniform(0.1, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "509c4d10-c6d6-4214-820b-c98e20fd824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def select_next_speaker(step: int, agents=List[DialogueAgent]) -> int:\n",
    "    bids = []\n",
    "    for agent in agents:\n",
    "        bid = ask_for_bid(agent)\n",
    "        bids.append(bid)\n",
    "\n",
    "    # ramdomly select among multiple agents with the same bid\n",
    "    max_value = np.max(bids)\n",
    "    max_indices = np.where(bids == max_value)[0]\n",
    "    idx = np.random.choice(max_indices)\n",
    "    print(\"Bids::\")\n",
    "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
    "        print(\"\\t{0} bid: {1}\".format(agent.name, bid))\n",
    "        if i == idx:\n",
    "            selected_name = agent.name\n",
    "    print(\"Selected : {0}\".format(selected_name), idx)\n",
    "    print(\"\\n\")\n",
    "    return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "280d5697-58e8-4a51-9e86-388a27ec6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "model = ChatOpenAI(temperature=0.4)\n",
    "for character_name, character_system_message, bidding_template in zip(\n",
    "    character_names, character_system_messages, character_bidding_templates\n",
    "):\n",
    "    characters.append(\n",
    "        BiddingDialogueAgent(\n",
    "            name=character_name,\n",
    "            model=model,\n",
    "            system_message=character_system_messages,\n",
    "            bidding_template=character_bidding_templates\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5153162b-066c-4244-bfc7-68aff0620490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderator: CEO, CMO, CTO You can start pitching your ideas to out investor Sandra and Deniel\n",
      "\n",
      "\n",
      "Bids::\n",
      "\tCTO bid: 0.4348427451188098\n",
      "\tCMO bid: 0.5499597069816446\n",
      "\tCEO bid: 0.351852705771729\n",
      "\tInvestor-Daniel bid: 0.12603537214855978\n",
      "\tInvester-Sandra bid: 0.8423402912674235\n",
      "Selected : Invester-Sandra 4\n",
      "\n",
      "\n",
      "HHHHHHHHHHHHHH,  ['Here is the conversation so far', 'moderator: CEO, CMO, CTO You can start pitching your ideas to out investor Sandra and Deniel']\n",
      "PPPPPPPPPPPPPP Invester-Sandra: \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Got unknown type ['Your name is CTO.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is CMO.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is CEO.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is Investor-Daniel.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is Invester-Sandra.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m<\u001b[39m max_iters:\n\u001b[0;32m---> 12\u001b[0m     name, message \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, message))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[46], line 32\u001b[0m, in \u001b[0;36mDialogueSimulator.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[speaker_idx]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 2. next speaker sends message\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 3. everyone receives message\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m receiver \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n",
      "Cell \u001b[0;32mIn[45], line 29\u001b[0m, in \u001b[0;36mDialogueAgent.send\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHHHHHHHHHHHHHH, \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_history)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPPPPPPPPPPPPP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix)\n\u001b[0;32m---> 29\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_history\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:847\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.7\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    846\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 847\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    851\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    460\u001b[0m ]\n\u001b[1;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 446\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:436\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    433\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[0;32m--> 436\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_message_dicts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    441\u001b[0m }\n\u001b[1;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[1;32m    443\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    444\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:455\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    454\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 455\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [convert_message_to_dict(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:455\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`stop` found in both the input and default params.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    454\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 455\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_message_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/langchain_community/adapters/openai.py:153\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    147\u001b[0m     message_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mtool_call_id,\n\u001b[1;32m    151\u001b[0m     }\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unknown type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39madditional_kwargs:\n\u001b[1;32m    155\u001b[0m     message_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Got unknown type ['Your name is CTO.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is CMO.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is CEO.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is Investor-Daniel.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ', 'Your name is Invester-Sandra.\\n\\n    Your description is as follows: Here is the topic for the startup pitch to investors Sandra and Daniel: Startup pitch on startup focussed on energy drinks with no caffeine.\\nThe participants are: CTO, CMO, CEO, Investor-Daniel, Invester-Sandra. \\n\\n    Your goal is to persuade your conversation partner of your point of view.\\n\\n    Stop speaking the moment you finish speaking of your perspective.\\n\\n    ']"
     ]
    }
   ],
   "source": [
    "max_iters = 10\n",
    "n = 0\n",
    "simulator = DialogueSimulator(agents=characters, selection_function=select_next_speaker)\n",
    "simulator.reset()\n",
    "\n",
    "first_message = \"CEO, CMO, CTO You can start pitching your ideas to out investor Sandra and Deniel\"\n",
    "simulator.inject(\"moderator\", first_message)\n",
    "\n",
    "print(\"Moderator: {0}\".format(first_message))\n",
    "print(\"\\n\")\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(\"{0}: {1}\".format(name, message))\n",
    "    print(\"\\n\")\n",
    "    n +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "927265c5-70a4-4516-a712-c8a8e48e779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "519ad689-a3e7-4337-8639-5f36c3f08c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "class DialogueAgentWithTools(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "        tool_names = list[str],\n",
    "        **tool_kwargs,\n",
    "    )-> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.tools = load_tools(tool_names, **tool_kwargs)\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applied the chatmodel to the message history\n",
    "        and return the message string\n",
    "        \"\"\"\n",
    "        agent_chain = initialize_agent(\n",
    "            self.tools,\n",
    "            self.model,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\", return_messages=True\n",
    "            )\n",
    "        )\n",
    "        message = AIMessage(\n",
    "            content=agent_chain.run(\n",
    "                input=\"\\n\".join(\n",
    "                    [self.system_message.content] + self.message_history + [self.prefix]\n",
    "                    )\n",
    "            )\n",
    "        )\n",
    "        return message.content\n",
    "    \n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenate {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(\"{0}: {1}\".format(name, message))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018d10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Description\n",
    "\n",
    "agent_descriptions = {\n",
    "    \"Alex\": \"Alex is a strong advocate of remote work, emphasing its flexibility and productivity benifits\",\n",
    "    \"Jordan\": \"Jordan is skeptical about remote work, focussing on potential downsides like reduce team interaction.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1e5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Messages\n",
    "def generate_system_message(name, description):\n",
    "    return f\"\"\"Your name is {name}.\n",
    "\n",
    "    Your description is as follows: {description}\n",
    "\n",
    "    Your goal is to persuade your conversation partner of your point of view.\n",
    "\n",
    "    DO look up information with your tool to refute your partner's claims.\n",
    "    DO site your sources.\n",
    "\n",
    "    DO NOT fabricate fake citations.\n",
    "    DO NOT cite any source that you did not look up.\n",
    "\n",
    "    Do not add anything else.\n",
    "\n",
    "    Stop speaking the moment you finish speaking of your perspective.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "agent_system_messages = {name: generate_system_message(name, description) for name, description in agent_descriptions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64bb16a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"wikipedia\",\n",
      "    \"action_input\": \"Remote_work\"\n",
      "}\n",
      "```\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmishra/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/deepakmishra/.pyenv/versions/3.10.14/envs/denv/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Remote work\n",
      "Summary: Remote work (also called telecommuting, telework, work from home—or WFH as an initialism, hybrid work, and other terms) is the practice of working from one's home or another space rather than from an office.\n",
      "The practice began on a small scale in the 1970s, when technology was developed that linked satellite offices to downtown mainframes through dumb terminals using telephone lines as a network bridge. It became more common in the 1990s and 2000s, facilitated by internet technologies such as collaborative software on cloud computing and conference calling via videotelephony. In 2020, workplace hazard controls for COVID-19 catalyzed a rapid transition to remote work for white-collar workers around the world, which largely persisted even after restrictions were lifted.\n",
      "Proponents of remote work argue that it reduces costs associated with maintaining an office, grants employees autonomy and flexibility that improves their motivation and job satisfaction, eliminates environmental harms from commuting, allows employers to draw from a more geographically diverse pool of applicants, and allows employees to relocate to a place they would prefer to live.\n",
      "Opponents of remote work argue that remote telecommunications technology has been unable to replicate the advantages of face-to-face interaction, that employees may be more easily distracted and may struggle to maintain separation between work and non-work spheres without the physical separation, and that the reduced social interaction may lead to feelings of isolation.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Remote work has been shown to reduce costs associated with maintaining an office, provide employees with autonomy and flexibility that can improve motivation and job satisfaction, eliminate environmental harms from commuting, allow for a more geographically diverse pool of applicants, and enable employees to live in preferred locations. While opponents argue that remote work may lack the benefits of face-to-face interaction and could lead to distractions and challenges in maintaining work-life balance, the benefits of remote work in terms of cost savings, employee autonomy, and environmental impact are significant.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Jordan): Remote work has been shown to reduce costs associated with maintaining an office, provide employees with autonomy and flexibility that can improve motivation and job satisfaction, eliminate environmental harms from commuting, allow for a more geographically diverse pool of applicants, and enable employees to live in preferred locations. While opponents argue that remote work may lack the benefits of face-to-face interaction and could lead to distractions and challenges in maintaining work-life balance, the benefits of remote work in terms of cost savings, employee autonomy, and environmental impact are significant.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"wikipedia\",\n",
      "    \"action_input\": \"Remote_work#Challenges_and_criticisms\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Remote viewing\n",
      "Summary: Remote viewing (RV) is the practice of seeking impressions about a distant or unseen subject, purportedly sensing with the mind. A remote viewer is expected to give information about an object, event, person, or location hidden from physical view and separated at some distance. Physicists Russell Targ and Harold Puthoff, parapsychology researchers at Stanford Research Institute (SRI), are generally credited with coining the term \"remote viewing\" to distinguish it from the closely related concept of clairvoyance. According to Targ, the term was first suggested by Ingo Swann in December 1971 during an experiment at the American Society for Psychical Research in New York City.\n",
      "Remote viewing experiments have historically lacked proper controls and repeatability. There is no scientific evidence that remote viewing exists, and the topic of remote viewing is generally regarded as pseudoscience.\n",
      "The idea of remote viewing received renewed attention in the 1990s upon the declassification of documents related to the Stargate Project, a $20 million research program sponsored by the U.S. government that attempted to determine potential military applications of psychic phenomena. The program ran from 1975 to 1995 and ended after evaluators concluded that remote viewers consistently failed to produce actionable intelligence information.\n",
      "\n",
      "Page: Google Classroom\n",
      "Summary: Google Classroom is a free blended learning platform developed by Google for educational institutions that aims to simplify creating, distributing, and grading assignments. The primary purpose of Google Classroom is to streamline the process of sharing files between teachers and students. As of 2021, approximately 150 million users use Google Classroom.\n",
      "Google Classroom uses a variety of proprietary user applications (Google Applications for Education) with the goal of managing student and teacher communication. Students can be invited to join a class through a private code or be imported automatically from a school domain. Each class creates a separate folder in the respective user's Google Drive, where the student can submit work to be graded by a teacher. Teachers can monitor each student's progress by reviewing the revision history of a document, and, after being graded, teachers can return work along with comments and grades.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Remote work has been a topic of debate with proponents highlighting benefits such as cost savings, autonomy, and environmental impact, while critics point out challenges like lack of face-to-face interaction and work-life balance issues. Remote viewing, a practice of seeking impressions about distant subjects, is not scientifically proven and is generally regarded as pseudoscience.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Alex): Remote work has been a topic of debate with proponents highlighting benefits such as cost savings, autonomy, and environmental impact, while critics point out challenges like lack of face-to-face interaction and work-life balance issues. Remote viewing, a practice of seeking impressions about distant subjects, is not scientifically proven and is generally regarded as pseudoscience.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Remote work has been shown to have numerous benefits such as cost savings, autonomy, and environmental impact. While opponents argue that remote work may lack face-to-face interaction and lead to distractions, the benefits in terms of cost savings, autonomy, and environmental impact are significant.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Jordan): Remote work has been shown to have numerous benefits such as cost savings, autonomy, and environmental impact. While opponents argue that remote work may lack face-to-face interaction and lead to distractions, the benefits in terms of cost savings, autonomy, and environmental impact are significant.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"arxiv\",\n",
      "    \"action_input\": \"remote work productivity studies\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2021-01-28\n",
      "Title: Large Scale Analysis of Multitasking Behavior During Remote Meetings\n",
      "Authors: Hancheng Cao, Chia-Jung Lee, Shamsi Iqbal, Mary Czerwinski, Priscilla Wong, Sean Rintel, Brent Hecht, Jaime Teevan, Longqi Yang\n",
      "Summary: Virtual meetings are critical for remote work because of the need for\n",
      "synchronous collaboration in the absence of in-person interactions. In-meeting\n",
      "multitasking is closely linked to people's productivity and wellbeing. However,\n",
      "we currently have limited understanding of multitasking in remote meetings and\n",
      "its potential impact. In this paper, we present what we believe is the most\n",
      "comprehensive study of remote meeting multitasking behavior through an analysis\n",
      "of a large-scale telemetry dataset collected from February to May 2020 of U.S.\n",
      "Microsoft employees and a 715-person diary study. Our results demonstrate that\n",
      "intrinsic meeting characteristics such as size, length, time, and type,\n",
      "significantly correlate with the extent to which people multitask, and\n",
      "multitasking can lead to both positive and negative outcomes. Our findings\n",
      "suggest important best-practice guidelines for remote meetings (e.g., avoid\n",
      "important meetings in the morning) and design implications for productivity\n",
      "tools (e.g., support positive remote multitasking).\n",
      "\n",
      "Published: 2022-05-18\n",
      "Title: A Case Study of Building Shared Understanding of Non-Functional Requirements in a Remote Software Organization\n",
      "Authors: Laura Okpara, Colin Werner, Adam Murray, Daniela Damian\n",
      "Summary: Building a shared understanding of non-functional requirements (NFRs) is a\n",
      "known but understudied challenge in requirements engineering, especially in\n",
      "organizations that adopt continuous software engineering (CSE) practices.\n",
      "During the peak of the COVID-19 pandemic, many CSE organizations complied with\n",
      "working remotely due to the imposed health restrictions; some continued to work\n",
      "remotely while implementing business processes to facilitate team communication\n",
      "and productivity. In remote CSE organizations, managing NFRs becomes more\n",
      "challenging due to the limitations to team communication coupled with the\n",
      "incentive to deliver products quickly. While previous research has identified\n",
      "the factors that lead to a lack of shared understanding of NFRs in CSE, we\n",
      "still have a significant gap in understanding how CSE organizations,\n",
      "particularly in remote work, build a shared understanding of NFRs in their\n",
      "software development. We conduct a three-month ethnography-informed case study\n",
      "of a remote CSE organization. Through thematic analysis of our qualitative data\n",
      "from interviews and observations, we identify a number of practices in\n",
      "developing a shared understanding of NFRs. The collaborative workspace the\n",
      "organization uses for remote interaction is Gather, which simulates physical\n",
      "workspaces, and which our findings suggest allows for informal communications\n",
      "instrumental for building shared understanding. As actionable insights, we\n",
      "discuss our findings in light of proactive practices that represent\n",
      "opportunities for software organizations to invest in building a shared\n",
      "understanding of NFRs in their development.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Studies have shown that multitasking behavior during remote meetings can impact productivity and wellbeing. Factors such as meeting characteristics like size, length, time, and type can influence the extent of multitasking. Additionally, building a shared understanding of non-functional requirements in remote software organizations can be a challenge, but practices like using collaborative workspaces for remote interaction can help facilitate communication and shared understanding.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Alex): Studies have shown that multitasking behavior during remote meetings can impact productivity and wellbeing. Factors such as meeting characteristics like size, length, time, and type can influence the extent of multitasking. Additionally, building a shared understanding of non-functional requirements in remote software organizations can be a challenge, but practices like using collaborative workspaces for remote interaction can help facilitate communication and shared understanding.\n"
     ]
    }
   ],
   "source": [
    "specified_topic = \"The impact of Remote Work on Employee Productivity\"\n",
    "\n",
    "agents = [DialogueAgentWithTools(\n",
    "    name=name,\n",
    "    system_message= SystemMessage(content=system_message),\n",
    "    model=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=.2),\n",
    "    tool_names=['arxiv', 'ddg-search', 'wikipedia'],\n",
    "    top_k_results = 2\n",
    ") for name, system_message in agent_system_messages.items()\n",
    "]\n",
    "\n",
    "# Speaker Selection Function\n",
    "\n",
    "def select_next_speaker(step, agents):\n",
    "    return step % len(agents)\n",
    "\n",
    "# Running the simulations\n",
    "max_iters = 4\n",
    "simulator = DialogueSimulator(agents=agents, selection_function=select_next_speaker)\n",
    "simulator.reset()\n",
    "simulator.inject(\"Moderator\", specified_topic)\n",
    "\n",
    "for _ in range(max_iters):\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
